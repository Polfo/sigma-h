#summary Breaking changes to the underlying SQL database schema
#labels Featured

= Introduction =

Every attempt will be made to keep new versions of Sigmah backwards compatible with SQL databases created with earlier versions of Sigmah/ActivityInfo, but sometimes there will be a need for breaking changes. These can be found here.


= Release 0.9 =

From 0.8.1 to 0.9, the following changes have to be performed on the schema:


{{{
DROP TABLE report;

ALTER TABLE project_model ADD COLUMN status VARCHAR(20) DEFAULT 'READY';
UPDATE project_model SET status = 'READY' WHERE status IS NULL;

ALTER TABLE Indicator CHANGE ActivityId ActivityId int(11) NULL;
ALTER TABLE Indicator CHANGE Units Units varchar(15) NULL;

ALTER TABLE locationtype CHANGE LocationTypeId LocationTypeId int(11) NOT NULL AUTO_INCREMENT; 

ALTER TABLE Site CHANGE ActivityId ActivityId int(11) NULL;

ALTER TABLE project ADD COLUMN activity_advancement INTEGER ;

ALTER TABLE log_frame_activity ADD COLUMN advancement INTEGER ;

ALTER TABLE projectreport ADD COLUMN orgunit_partnerid INTEGER ;
}}}


Delete the column "Title" of table "Log_frame". Logframe does not handle its own title.

{{{

ALTER TABLE log_frame DROP COLUMN title;

}}}


= Release 0.70 =

A large number of domain objects have been added since the last full release of ActivityInfo (0.5.11). Users are advised to let hibernate create a new schema and import your existing data into the new structure with a mapping tool.

[http://opendbcopy.sourceforge.net/ OpenDbCopy] is a good tool that we have used for ActivityInfo.org.

* WARNING *: Do NOT attempt to use hibernate's schema update feature on production data! This is a [http://stackoverflow.com/questions/221379/hibernate-hbm2ddl-autoupdate-in-production good posting] on why this is not OK.

In addition, to use the new offline features, you will need to update your data to meet certain assumptions made by the synchronization module. 

Specifically, the synchronizer uses timestamps to divide updates into batches. Since early versions of AI did not maintain timestamps, your database may have a large number of records with the same timestamp. Future versions of AI/Sigmah may be capable of more sophisticated batching but for the time being you can "salt" your data with the following SQL:

{{{
UPDATE Location SET dateEdited = date_add(dateEdited, INTERVAL LocationId SECOND) where second(dateEdited) = 0;

UPDATE Site SET dateEdited = date_add(dateEdited, INTERVAL LocationId SECOND) where second(dateEdited) = 0;
}}}
 


= Revision r138 = 

  * The columns !changePasswordKey and !dateChangePasswordKeyIssued have been added to the !UserLogin table

{{{
alter table UserLogin add changePasswordKey nvarchar(64)
alter table UserLogin add dateChangePasswordKeyIssued date
}}}


= November 30, 2009 / Release 0.5.6 =

  * The columns !ManageUsers, !ManageAllUsers have been added to the !UserPermissions table.
{{{
ALTER TABLE UserPermission ADD
  AllowManageUsers bit NOT NULL 
     CONSTRAINT DF_UserPermission_AllowManageUsers DEFAULT 0,
  AllowManageAllUsers bit NOT NULL 
     CONSTRAINT DF_UserPermission_AllowManageAllusers DEFAULT 0
}}}